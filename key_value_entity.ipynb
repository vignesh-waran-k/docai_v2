{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ed1d8d-6e1b-46b9-9063-43795a8910d9",
   "metadata": {},
   "source": [
    "# Key value pair to entity Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e64f8-6bb0-4b3f-91c3-5801fc211e44",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae17bc-144a-457d-87a4-5e293eead7e7",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325f4e0-5120-4c22-96d9-bd8b5051ea78",
   "metadata": {},
   "source": [
    "## Purpose and Description\n",
    "This tool uses Form parser JSON files (Parsed from a processor) from the GCS bucket as input, converts the key/value pair to the entities and stores it to the GCS bucket as JSON files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ce959-76b1-4f53-b750-3d5f213a8782",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Vertex AI Notebook\n",
    "2. Form parser Json files  in GCS Folders.\n",
    "3. Output folder to upload the updated json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278aba8d-976f-4171-866a-2446b2e56322",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: configparser in /opt/conda/lib/python3.7/site-packages (5.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for notebook: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/notebook-6.5.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/nest_asyncio-1.5.6.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nbclassic: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/nbclassic-0.5.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for jupyter-client: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/jupyter_client-7.4.9.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud in /opt/conda/lib/python3.7/site-packages (0.34.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for notebook: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/notebook-6.5.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/nest_asyncio-1.5.6.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nbclassic: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/nbclassic-0.5.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for jupyter-client: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/jupyter_client-7.4.9.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.64.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for notebook: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/notebook-6.5.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nest-asyncio: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/nest_asyncio-1.5.6.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for nbclassic: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/nbclassic-0.5.3.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing requirements for jupyter-client: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/jupyter_client-7.4.9.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install configparser\n",
    "%pip install google-cloud\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b592c-7fb0-4db4-9d49-926e7ef5f8ec",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b7bcc-3303-48a9-803f-35e48da9732a",
   "metadata": {},
   "source": [
    "### 1. Config file Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed44f6cc-c826-4452-8c69-7a8b796f5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config_path= \"config.ini\" #Enter the path of config file\n",
    "# Add the structure to the file we will create\n",
    "config.add_section('Entities_synonyms')\n",
    "config.set('Entities_synonyms', 'entity1', 'key_synonym1, key_synonym2, key_synonym3')\n",
    "config.set('Entities_synonyms', 'entity2', 'key_synonym1, key_synonym2, key_synonym3')\n",
    "# Write the new structure to the new file\n",
    "with open(config_path, 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90bed7-66ec-4548-85d6-f77812915b19",
   "metadata": {},
   "source": [
    "### 2. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681950f-152d-460b-b186-131c46c9578e",
   "metadata": {},
   "source": [
    "#### a. Once config.ini file is created with the above step , enter the input in the config file : \n",
    "\n",
    "entity1 =  key_synonym1, key_synonym2, key_synonym3\n",
    "\n",
    "<img src=\"./Images/key_value_entity_input_1.png\" width=800 height=400 alt=\"Key value pair entitiy conversion input image\">\n",
    "Here add the entity name in place of entity1 and  add the synonyms related to the entity in place of key_synonym separated by comma(,). Add multiple entities with their synonyms in the next line.\n",
    "\n",
    "<div style=\"background-color:#ADD8E6; border:1px solid black; padding:5px\">\n",
    "<i><b>Example</b></i> : <br> \n",
    "Address = AddressName, AddressName1, AddressLine<br>\n",
    "InvoiceNumber = Invoice,InvoiceNo<br>\n",
    "PaymentDate = SNC, SNCs, SNC1<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c2fc8a-b64b-485d-be06-9174010b9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031cad5-9181-43ab-b161-adba326d0195",
   "metadata": {},
   "source": [
    "#### b. Copy the code provided in this document, Enter the path of Config file\n",
    "<img src=\"./Images/key_value_entity_input_2.png\" width=800 height=400 alt=\"Key value pair entitiy conversion input image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37209eb5-7a81-4558-8e22-e9a30df4e5e0",
   "metadata": {},
   "source": [
    "#### c. Update the Parser input path and the GCP output for the output Jsons.\n",
    "<img src=\"./Images/key_value_entity_input_3.png\" width=800 height=400 alt=\"Key value pair entitiy conversion input image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a8e16-6a2a-4899-b854-a32725007777",
   "metadata": {},
   "source": [
    "### 3. Output\n",
    "\n",
    "We get the converted Json in the GCS path which is provided in the script with the variable name output_path . \n",
    "<img src=\"./Images/key_value_entity_output_1.png\" width=800 height=400 alt=\"Key value pair entitiy conversion output image\">\n",
    "\n",
    "<table style=\"border: 1px solid black;padding:0px; margin:0px\">\n",
    "    <tr style=\"border: 1px solid black;padding:0px; margin:0px\">\n",
    "    <td style=\"text-align:center;border: 1px solid black;padding:0px; margin:0px\"><h2>Before</h2></td>\n",
    "    <td  style=\"text-align:center;border: 1px solid black;padding:0px; margin:0px\"><h2>After</h2></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"border: 1px solid black;padding:0px; margin:0px\"><img src=\"./Images/key_value_pair_output_comparison_1.png\" width=600 height=800 alt=\"Key value pair entitiy comparison output image\"></td>\n",
    "    <td style=\"border: 1px solid black;padding:0px; margin:0px\"><img src=\"./Images/key_value_pair_output_comparison_2.png\" width=600 height=800 alt=\"Key value pair entitiy comparison output image\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caacdb9-4198-4c7c-8579-5fc403077b05",
   "metadata": {},
   "source": [
    "### 4. Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65824d3-7f36-487f-8a41-7dbcccb9b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary modules\n",
    "\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
    "from utilities import documentai_json_proto_downloader,store_document_as_json, file_names\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "INPUT_PATH = \"gs://xxxx/xxxxxxxx/xxxxxxxxxx\" # path of the form parser output\n",
    "OUTPUT_PATH = \"gs://xxxxxxxxx/xxxxxxxxx/xxxxx\" # output path for this script\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.optionxform = str\n",
    "config.read(config_path)\n",
    "\n",
    "\n",
    "\n",
    "def entity_synonyms(old_entity : str) -> str : \n",
    "    \"\"\"\n",
    "    To check for any synonyms for the entites and replace it with the entity name provided \n",
    "    by the user. \n",
    "\n",
    "    Args:\n",
    "        old_entity : The key name from the input document .\n",
    "\n",
    "    Returns:\n",
    "        str  : Returns the matched entity name provided by the user.\n",
    "    \"\"\"\n",
    "    entities_synonyms = config.items('Entities_synonyms')\n",
    "    for item in entities_synonyms:\n",
    "        synonym_list = [i.lower().strip() for i in item[1].split(\",\")]\n",
    "        \n",
    "        if old_entity.lower() in synonym_list:    \n",
    "            return item[0]\n",
    "            \n",
    "    #if entity does not match with any synonyms, will return entity as it is.\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def entity_data(formField_data : documentai.Document.Page.FormField,page_number : int) -> documentai.Document.Entity :\n",
    "    \"\"\"\n",
    "    Function to create entity objects with some cleaning.\n",
    "\n",
    "    Args:\n",
    "        formField_data:documentai.Document.Page.FormField : The form fields having the key value information\n",
    "        inside the entity.\n",
    "        page_number : int : The page number from the input documents\n",
    "\n",
    "    Returns:\n",
    "        documentai.Document.Entity: The entity which are converted from key and value.\n",
    "    \"\"\"\n",
    "    #Cleaning the entity name \n",
    "    key_name = re.sub('[^\\w\\s]',\"\",formField_data.field_name.text_anchor.content).replace(\" \",\"\").strip()\n",
    "    #checking for entity synonyms\n",
    "    key_name = entity_synonyms(key_name)\n",
    "    \n",
    "    if key_name:\n",
    "        entity_dict = {\n",
    "        \"confidence\" :  formField_data.field_value.confidence,\n",
    "        \"mention_text\" : formField_data.field_value.text_anchor.content,\n",
    "        \"page_anchor\" :{ \"page_refs\":[{\"bounding_poly\":formField_data.field_value.bounding_poly, \n",
    "                                       \"page\":page_number}]},\n",
    "        \"text_anchor\" : formField_data.field_value.text_anchor,\n",
    "        \"type\" : key_name\n",
    "        }\n",
    "\n",
    "        return entity_dict\n",
    "    else:\n",
    "        return None\n",
    "          \n",
    "\n",
    "def convert_kv_entities(document : documentai.Document)-> documentai.Document:\n",
    "    \"\"\"\n",
    "    Function to convert form parser key value to entities. \n",
    "\n",
    "    Args:\n",
    "        document:documentai.Document : The original document object from gcp storage.\n",
    "\n",
    "    Returns:\n",
    "        documentai.Document: The converted document object .\n",
    "    \"\"\"\n",
    "\n",
    "    #initializing entities list\n",
    "    document.entities = []\n",
    "    \n",
    "    for page_number, page_data in enumerate(document.pages):\n",
    "        for formField_number,formField_data in enumerate(page_data.form_fields):\n",
    "            \n",
    "            #get the element and push it to the entities array \n",
    "            entity_obj = entity_data(formField_data, page_number)\n",
    "            if entity_obj:\n",
    "                document.entities.append(entity_obj)\n",
    "            \n",
    "    #removing the form parser data\n",
    "    for i in range(len(document.pages)) :\n",
    "        if document.pages[i].form_fields:\n",
    "            del document.pages[i].form_fields\n",
    "\n",
    "        if document.pages[i].tables:\n",
    "            del document.pages[i].tables\n",
    "            \n",
    "    return document\n",
    "     \n",
    "def main()->None:\n",
    "    \"\"\"\n",
    "    Main function to call helper functions\n",
    "    \n",
    "    \"\"\"\n",
    "    # fetching all the files\n",
    "    input_bucket_name = INPUT_PATH.split('/')[2]\n",
    "    input_prefix_path = \"/\".join(INPUT_PATH.split('/')[3:])\n",
    "    output_bucket_name = OUTPUT_PATH.split('/')[2]\n",
    "    output_prefix_path = \"/\".join(OUTPUT_PATH.split('/')[3:])\n",
    "    file_name_list = [i for i in  list(file_names(INPUT_PATH)[1].values()) if i.endswith(\".json\")]\n",
    "    \n",
    "    for file_name in tqdm(file_name_list,desc =\"Status : \"):\n",
    "        try:\n",
    "            # converting key value to entites\n",
    "            document = documentai_json_proto_downloader(input_bucket_name,file_name)\n",
    "            converted_document = convert_kv_entities(document)\n",
    "\n",
    "            #storing the document\n",
    "            output_file_name = f\"{output_prefix_path}/{file_name.split('/')[-1]}\"\n",
    "            store_document_as_json(documentai.Document.to_json(converted_document),\n",
    "                                   output_bucket_name,output_file_name)\n",
    "            print(f\"[✓] {output_bucket_name}/{output_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[x] {input_bucket_name}/{file_name} || Error : {str(e)}\")\n",
    "    print('\\nOperation completed')\n",
    "#calling main function    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e90b9d-040f-4b52-89ef-681a5cef8753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
